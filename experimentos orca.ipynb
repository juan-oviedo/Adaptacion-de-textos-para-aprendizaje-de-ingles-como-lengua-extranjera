{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da3741b-1842-403d-b9e0-0cbfbec38b69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51964b4b-7825-41b9-aee7-0fbea179584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as sk\n",
    "import gc\n",
    "import transformers\n",
    "import torch\n",
    "import csv\n",
    "import re\n",
    "import subprocess\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92afce-437c-4e1d-9b9c-bf530457b7a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Carga de datos y division del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbe8550-0450-4a14-b245-3d2fcc3a51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the zip file is present and has been unzipped\n",
    "if not os.path.exists(\"cefr-levelled-english-texts.zip\"):\n",
    "    # Download the dataset if the zip file is not present\n",
    "    !kaggle datasets download -d amontgomerie/cefr-levelled-english-texts\n",
    "\n",
    "if not os.path.exists(\"cefr_leveled_texts.csv\"):  # Adjust this to match the folder name after unzipping\n",
    "    # Unzip the file if the unzipped folder does not exist\n",
    "    !unzip cefr-levelled-english-texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484f814d-a0d8-4014-8bd3-7348081e3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1161849/887818524.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('label').apply(lambda x: x.sample(n=min_samples, random_state=60)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('cefr_leveled_texts.csv')\n",
    "\n",
    "# Get the minimum number of samples in any class\n",
    "min_samples = df['label'].value_counts().min()\n",
    "\n",
    "# Downsample each class to have the same number of samples as the smallest class\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(n=min_samples, random_state=60)).reset_index(drop=True)\n",
    "\n",
    "distribution = df_balanced['label'].value_counts()\n",
    "train, div = sk.train_test_split(df_balanced, test_size=0.2, random_state=70)\n",
    "dev, holdout = sk.train_test_split(div, test_size=0.5, random_state=50)\n",
    "#holdout, dev = sk.train_test_split(div, test_size=0.08, random_state=50)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "div = div.reset_index(drop=True)\n",
    "holdout = holdout.reset_index(drop=True)\n",
    "\n",
    "textos_metricas = pd.concat([dev, train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705b23f-eda1-4c04-9527-56c35a0d76e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34833618-4b9c-4644-8b51-e45da1df3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_lecto = \"you are an English teacher and I want you to classify the following text according to the CEFR classes. I want you to responds only with the class (A1|B1|C1|A2|B2|C2). without introduction.\"\n",
    "con_lecto = \"you are an English teacher and I want you to classify the following text for reading comprehension according to the CEFR classes. I want you to responds only with the class (A1|B1|C1|A2|B2|C2). without introduction.\"\n",
    "correccion = \"I detect that you have a bias to classify everything as B2, correct it.\"\n",
    "\n",
    "propmt_1 = \"Can you classify the following text according to its Common European Framework of Reference (CEFR) readibility level? I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "propmt_2 = \"I'm a teacher of English who is preparing a reading task. Can you classify the following text regarding its readibility based on the CEFR? I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "propmt_3 = \"I'm a teacher of English as a foreign language. I'm preparing  a reading task for my students and I would like to use the following text. Can you tell me which CEFR level is the following text suitable for? I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "propmt_4 = \"I'm a teacher of English as a foreign language. I'm preparing  a reading task for my students and I would like to use the following text. Can you classify the following test according to its CEFR readibility level? I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "propmt_5 = \"I'm a teacher of English as a foreign language. I'm preparing  a reading task for my students and I would like to use the following text. Can you annotate the following test according to its CEFR readibility level? I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "\n",
    "header_A1 = \"this is an example of a text for level A1\"\n",
    "header_A2 = \"this is an example of a text for level A2\"\n",
    "header_B1 = \"this is an example of a text for level B1\"\n",
    "header_B2 = \"this is an example of a text for level B2\"\n",
    "header_C1 = \"this is an example of a text for level C1\"\n",
    "header_C2 = \"this is an example of a text for level C2\"\n",
    "\n",
    "ejemplo_1_A1 = \"Let's play in the pool, Helen.\\nOkay, Linda. \\nIt's fun.\\nIt's so hot today.\\nNot in the pool.\\nI know. I like it here.\\nWe can do this every day.\\nSure, we can, Linda.\"\n",
    "ejemplo_2_A1 = \"Hi Lisa. How are you? \\nI'm fine. What are you doing?\\nI'm reading a book.\\nReally? All of it?\\nNo. Just this part.\\nWho's that?\\nIt's Mary. She has a dog.\\nLet's read it together.\"\n",
    "ejemplo_1_A2 = \"I have a 89.5%.\\nOkay, so what?\\nIt's really close to an A.\\nYou know I don't round up.\\nBut I really need a 4.0 GPA.\\nYou get what you deserve.\\nI know I deserve an A. I always do great work and participate.\\nI can't change it.\\nPlease? I'll wash your car.\\nAre you bribing me?\\nI just want an A.\\nI'll give you a C if you don't leave now.\"\n",
    "ejemplo_2_A2 = \"The parking permit is $200 per semester, right?\\nIt's actually $300.\\nWhy?! That's ridiculous.\\nIt's because of the budget cuts.\\nThat's a terrible excuse.\\nIt's the truth.\\nGive me something better than that.\\nMiss, if you don't want to pay, then don't.\\nThis is so stressful.\\nI advise writing a letter to the dean.\\nI bet he'll just throw it away.\\nYou would be surprised.\"\n",
    "ejemplo_1_B1 = \"Bruce picked up the cat. The cat meowed. The cat didn't like most people. The cat liked to be alone. It liked to sleep on the sofa. It liked to sleep in the fruit bowl. It liked to sleep on top of the TV. It liked to chase bugs in the front yard. It liked to chase lizards in the back yard. It liked to chase flies in the kitchen. Bruce put the cat on the floor. He rubbed the cat's stomach. The cat liked that. The cat licked his hand. Bruce rubbed the cat's stomach some more. The cat meowed. The cat was happy.\"\n",
    "ejemplo_2_B1 = \"Bob pushed the button on the door handle. He pulled on the door handle. He opened the car door. He got into the car. He sat down. He sat down in the driver's seat. He sat down behind the steering wheel. Bob put the seat belt on. He buckled the seat belt. The seat belt went across his chest. The seat belt went across his lap. The seat belt kept him safe. He put his car key into the ignition. The ignition was next to the steering wheel. The ignition starts a car. Bob turned the car key in the ignition. The car started.\"\n",
    "ejemplo_1_B2 = \"Legendary football coach and broadcaster John Madden is retiring, he announced Thursday.\\nJohn Madden appears at the TV Critics Association Press Tour in Beverly Hills, California, in 2008.\\n It's been such a great ride... the NFL has been my life for more than 40 years, it has been my passion -- it still is, he said in a statement released by NBC Sports.\\nMadden, 73, was a Hall of Fame coach for the Oakland Raiders, but is best known to millions as an ebullient football commentator.\\nHe won 16 Emmy awards for outstanding sports analyst/personality, NBC said.\\n\"\n",
    "ejemplo_2_B2 = \"Dear Professor Henley,\\nI am writing to inform you that, unfortunately, I am unable to continue to attend the Logic II course this semester. I would like to request permission to defer as I understand that this is only possible with your approval.\\nThe issue is that I am currently doing an internship with ABC Ltd. It started in July and will continue until the end of the semester. The internship takes up 25 hours per week and I am concerned that it does not leave me with enough time to study. I have already asked if I can reduce my hours there, but this is not possible.\\nWith your approval, I could take Logic II next semester instead. I realise that this would mean a heavier workload than usual next semester, but I assure you that I would be able to manage my time and keep up.\\nThank you for considering my request and I would be happy to come in and discuss the matter further.\\nRegards,\\nSarah Price\"\n",
    "ejemplo_1_C1 = \"Dear Ms Leitman,\\nI am writing to request your help following a change in my circumstances.\\nAs you know, I am enrolled on the Basic Spanish course at your college, which starts in September. However, due to unforeseen family events, I have had to leave the country for a while to assist my parents in Hong Kong.\\nAt present it is not clear when I will be able to return and unfortunately I will not be able to start the course as planned.\\nI would like to request a refund for the course fees already paid. I apologise for the short notice and for any inconvenience caused. In the event that a refund is not possible, I would be grateful if you could postpone my enrolment until my return.\\nThank you in advance for your help and I hope to be able to update you on the situation soon.\\nYours sincerely,\\nHonor Singh\"\n",
    "ejemplo_2_C1 = \"-LRB- CNN -RRB- Spain is officially clear of Ebola, the World Health Organization declared Tuesday, after no new cases were reported since a nurse's assistant who contracted the virus there tested negative for it.\\nSince then, 42 days have passed -- double the maximum known incubation period for the virus -- without another case, allowing Spain to be declared free of Ebola.\\nSpanish authorities had been monitoring 87 people who came into contact with healthcare worker Teresa Romero Ramos, 15 of whom were considered high-risk and were quarantined at a Madrid hospital, WHO said.\\nAnother 145 hospital employees who helped care for Romero during her month-long stay at the Carlos III Hospital were also monitored.\\nThe WHO statement said it commends Spain for the measures put in place to identify potential cases and prevent further transmission of the Ebola virus. \\nRomero contracted the illness while helping to care for an infected missionary who had been brought back from West Africa. He died of the disease.\\nCNN's Anna Maja Rappard contributed to this report.\\n\"\n",
    "ejemplo_1_C2 = \"Twelve photographers from four continents have been shortlisted for the fourth Prix Pictet award in photography and sustainability.\\nThis year's theme of Power, has enormous breadth, embracing contradiction and paradox in equal measure that has uncovered images and issues that are both awe-inspiring and disturbing, organizers say.\\nThe aim of the award is to use the power of photography to raise public awareness of the social and environmental challenges of the new millennium.\\nThe winner will be announced by Kofi Annan, the awardshonorary president, in October at the opening of the finalistsexhibition of the shortlisted works at the Saatchi Gallery in London. The exhibition runs from the 10th to the 28th of October 2012.\\n\"\n",
    "ejemplo_2_C2 = \"Singapore's economy shrank by 4.2 percent in the fourth quarter of 2008, the Ministry of Trade and Industry said Thursday, as it forecast the economy would contract between 2 and 5 percent this year.\\nBoats ply under a bridge near the financial district of Singapore.\\nCompared to a robust growth of 7.8 percent a year earlier, the economy grew by 1.1 percent for the whole of 2008, the ministry added.\\nIt called Gross Domestic Product growth prospects for 2009 weak... on account of the pessimistic global economic outlook. \\nAll major sectors, except for construction, business services and information and communications, saw contractions, the ministry said.\\nThe ministry cited a decline in private sector investments and private consumption expenditure for dragging down total domestic demand.\\nDeclines in global demand for electronics products, pharmaceuticals and chemicals were also likely to weigh on the manufacturing sector.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c449dc-1110-456d-ab1f-306bdee8716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmt_descriptores=\"Using the above descriptors I want you to classify the following text according to its Common European Framework of Reference (CEFR) level. I want you to responds only with the class (A1|B1|C1|A2|B2|C2)\"\n",
    "\n",
    "\n",
    "header_des_A1 = \"this is a list of CEFR level descriptors for level A1:\"\n",
    "header_des_A2 = \"this is a list of CEFR level descriptors for level A2:\"\n",
    "header_des_B1 = \"this is a list of CEFR level descriptors for level B1:\"\n",
    "header_des_B2 = \"this is a list of CEFR level descriptors for level B2:\"\n",
    "header_des_C1 = \"this is a list of CEFR level descriptors for level C1:\"\n",
    "header_des_C2 = \"this is a list of CEFR level descriptors for level C2:\"\n",
    "\n",
    "descriptores_A1 = r\"\"\"very short, simple texts.\n",
    "short, simple messages on postcards.\n",
    "short, simple messages sent via social media or e-mail (e.g. proposing what to do, when and where to meet).\n",
    "store guides (information on which floors departments are on) and directions (e.g. where to find lifts).\n",
    "basic hotel information (e.g. times when meals are served).\n",
    "simple, important information in advertisements, programmes for special events, leaflets and brochures (e.g. what is proposed, costs, the date and place of the event, departure times).\n",
    "short, simple descriptions, especially if there is visual support.\n",
    "short texts on subjects of personal interest (e.g. news flashes about sports, music, travel or stories) composed in very simple language and supported by illustrations and pictures.\n",
    "simple messages written by friends or colleagues, for example \"back at 4 o’clock”.\n",
    "familiar names, words and basic phrases.\n",
    "familiar names, words/signs and very basic phrases on simple notices in the most common everyday situations.\n",
    "very simple language.\n",
    "direct commands (e.g., “open the door”).\n",
    "descriptions of clothes (pattern, colour).\n",
    "proportions, quantities, and size ratios.\n",
    "simple negation with <no>, <not>.\n",
    "a direct request, question or order.\n",
    "lists and sequences (<and>/<both-and>/<and then>\n",
    "time indicators (<day-before-yesterday>, <3-years-ago>, etc.), when the time references are clearly indicated.\n",
    "words and phrases on everyday signs (for example \"station”, \"car park”, \"no parking”, \"\"no smoking”, \"keep left”).\"\"\"\n",
    "\n",
    "descriptores_A2=\"\"\"Short, simple texts.\n",
    "Short, simple personal letters.\n",
    "Simple everyday material such as advertisements, prospectuses, menus, reference lists and timetables.\n",
    "everyday signs and notices, etc. in public places, such as streets, restaurants, railway stations; in workplaces, such as directions, instructions, hazard warnings.\n",
    "texts describing people, places, everyday life and culture, etc., provided they use simple language.\n",
    "information given in illustrated brochures and maps (e.g. the principal attractions of a city).\n",
    "main points in short news items on subjects of personal interest (e.g. sport, celebrities).\n",
    "short factual description or report within their own field, provided simple language is used and that it does not contain unpredictable detail.\n",
    "what people say about themselves in a personal ad or post and what they say they like in other people.\n",
    "simple instructions on equipment encountered in everyday life – such as a public telephone.\n",
    "simple, brief instructions, provided they are illustrated and not presented in continuous text.\n",
    "a simple recipe, especially if there are pictures to illustrate the most important steps.\n",
    "short narratives and descriptions of someone’s life composed in simple language.\n",
    "short description of a person (e.g. a celebrity).\n",
    "very short, simple texts by understanding familiar names, words and basic phrases.\n",
    "basic information in posters, adverts or catalogues.\n",
    "short simple greetings and messages e.g. on birthday cards, party invitations or in SMS phone messages.\n",
    "short simple messages from friends. For example: e-mails, web chats, postcards or short letters.\n",
    "highest frequency vocabulary, including a proportion of shared international vocabulary items.\n",
    "simple commands (e.g. “Take before meals” or “Do not take if driving”).\n",
    "simple language.\n",
    "high frequency everyday language.\n",
    "details in an extensive description of a person/object, such as body shape, hairstyle, or occupation.\n",
    "simple instructions, wishes, recommendations, etc.\n",
    "basic causal relations (e.g., “I’m late because I got stuck in the traffic”).\n",
    "indirect messages (questions, requests, wishes, rejection, etc.).\n",
    "different ways of expressing negation.\"\"\"\n",
    "\n",
    "descriptores_B1= r\"\"\"straightforward factual texts on subjects related to their field of interest.\n",
    "description of events, feelings and wishes in personal letters.\n",
    "straightforward personal letters, e-mails or postings giving a relatively detailed account of events and experiences.\n",
    "standard formal correspondence and online postings in their area of professional interest.\n",
    "relevant information in everyday material, such as letters, brochures and short official documents.\n",
    "information about preparation and usage on the labels on foodstuff and medicine.\n",
    "information in simple, clearly drafted adverts in newspapers or magazines, provided there are not too many abbreviations.\n",
    "main points in descriptive notes such as those on museum exhibits and explanatory boards in exhibitions.\n",
    "clearly expressed, straightforward instructions for a piece of equipment.\n",
    "simple instructions given on packaging (e.g. cooking instructions).\n",
    "short safety instructions, (e.g. on public transport or in manuals for the use of electrical equipment).\n",
    "descriptions of places, events, explicitly expressed feelings and perspectives in narratives, guides and magazine articles that employ high frequency everyday language.\n",
    "travel diary mainly describing the events of a journey and the experiences and discoveries of the writer.\n",
    "the plot of stories, simple novels and comics with a clear linear storyline and high frequency everyday language.\n",
    "brochures, leaflets and other short texts relating to my interests\n",
    "short newspaper and magazine articles about current and familiar topics.\n",
    "simple instructions, for example for a game, using familiar types of equipment or cooking a meal.\n",
    "simplified versions of novels, and follow the story line in short stories with a clear structure.\n",
    "private letters about events, feelings and wishes.\n",
    "high frequency everyday language.\"\"\"\n",
    "\n",
    "descriptores_B2= r\"\"\"correspondence relating to their field of interest and readily grasp the essential meaning.\n",
    "a personal e-mail or posting even where some colloquial language is used.\n",
    "articles and reports concerned with contemporary problems in which particular stances or viewpoints are adopted.\n",
    "lengthy, complex instructions in their field, including details on conditions and warnings.\n",
    "novels with a strong, narrative plot and that use straightforward, unelaborated language.\n",
    "articles, reports and reviews in which the writers express specific points of view (e.g., political commentary, critiques of exhibitions, plays, films, etc).\n",
    "lengthy instructions, for example in a user manual for a TV or digital camera, for installing software.\n",
    "short stories and novels written in a straightforward language and style, if I am familiar with the story and/or the writer.\n",
    "main points in formal and informal letters relating to my personal and professional interests.\n",
    "verbal aspect (e.g., completion, repetition, continuation, result of actions).\n",
    "idioms.\n",
    "various temporal relationships between the actions and events (simultaneous events, previous event, subsequent event).\n",
    "direct and indirect speech.\n",
    "statements that contain predicates that take no agent, e.g., “the water is flowing now”.\n",
    "rhetorical questions even if linguistically expressed in a very economical way, e.g., by raising the eyebrows.\"\"\"\n",
    "\n",
    "descriptores_C1= r\"\"\"lengthy, complex texts, whether or not these relate to their own area of speciality.\n",
    "a wide variety of texts including literary writings, newspaper or magazine articles, and specialised academic or professional publications.\n",
    "any correspondence.\n",
    "implicit as well as explicit attitudes, emotions and opinions expressed in e-mails, discussion forums, vlogs/blogs, etc\n",
    "slang, idiomatic expressions and jokes in private correspondence.\n",
    "a wide range of lengthy, complex texts likely to be encountered in social, professional or academic life.\"\"\"\n",
    "\n",
    "descriptores_C2= r\"\"\"all types of texts including abstract, structurally complex, or highly colloquial literary and non-literary writings.\n",
    "a wide range of long and complex texts.\n",
    "specialized, formal correspondence on a complex topic.\n",
    "a complex report or article even outside their area of specialization.\n",
    "all forms of texts including classical or colloquial literary and non-literary texts in different genres.\n",
    "lengthy, complex texts, whether or not they relate to my area of speciality.\n",
    "complex reports, analyses and commentaries in which opinions, viewpoints and connections are discussed.\n",
    "complex manuals, regulations and contracts even within unfamiliar fields.\n",
    "formal or informal correspondence.\n",
    "any kind of text including those written in a very colloquial style and containing many idiomatic expressions or slang.\n",
    "texts (for example newspaper columns and satirical glosses) in which much is said in an indirect and ambiguous way and which contain hidden value judgements..\n",
    "classical as well as contemporary literary texts in different genres.\n",
    "formal correspondence, including on specialized or legal matters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb02d7bb-1957-4657-aa07-9bf106424494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 SHOT:\n",
    "propmt_0shot_sin_lecto = sin_lecto\n",
    "propmt_0shot_con_lecto = con_lecto\n",
    "\n",
    "prompt_0shot_sin_lecto_correccion = sin_lecto + \"\\n\" + correccion\n",
    "prompt_0shot_con_lecto_correccion = con_lecto + \"\\n\" + correccion\n",
    "\n",
    "    #PROMPS ELI\n",
    "\n",
    "# 1 SHOT:\n",
    "propmt_1shot_sin_lecto =( header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" +\n",
    "                          header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" +\n",
    "                          header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" +\n",
    "                          header_B2 + \"\\n\" + ejemplo_1_B2 + \"\\n\" +\n",
    "                          header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" +\n",
    "                          header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" +\n",
    "                          sin_lecto)\n",
    "\n",
    "propmt_1shot_con_lecto =( header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" +\n",
    "                          header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" +\n",
    "                          header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" +\n",
    "                          header_B2 + \"\\n\" + ejemplo_1_B2 + \"\\n\" +\n",
    "                          header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" +\n",
    "                          header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" +\n",
    "                          con_lecto)\n",
    "\n",
    "prompt_1shot_sin_lecto_correccion = propmt_1shot_sin_lecto + \"\\n\" + correccion\n",
    "prompt_1shot_con_lecto_correccion = propmt_1shot_con_lecto + \"\\n\" + correccion\n",
    "\n",
    "prompt_1shot_sin_lecto_sacando_b2 =(header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" +\n",
    "                                    header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" +\n",
    "                                    header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" +\n",
    "                                    header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" +\n",
    "                                    header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" +\n",
    "                                    sin_lecto)\n",
    "\n",
    "prompt_1shot_con_lecto_sacando_b2 =(header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" +\n",
    "                                    header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" +\n",
    "                                    header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" +\n",
    "                                    header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" +\n",
    "                                    header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" +\n",
    "                                    con_lecto)\n",
    "\n",
    "# 2 SHOT:\n",
    "propmt_2shot_sin_lecto =( header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" + header_A1 + \"\\n\" + ejemplo_2_A1 + \"\\n\" +\n",
    "                          header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" + header_A2 + \"\\n\" + ejemplo_2_A2 + \"\\n\" +\n",
    "                          header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" + header_B1 + \"\\n\" + ejemplo_2_B1 + \"\\n\" +\n",
    "                          header_B2 + \"\\n\" + ejemplo_1_B2 + \"\\n\" + header_B2 + \"\\n\" + ejemplo_2_B2 + \"\\n\" +\n",
    "                          header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" + header_C1 + \"\\n\" + ejemplo_2_C1 + \"\\n\" +\n",
    "                          header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" + header_C2 + \"\\n\" + ejemplo_2_C2 + \"\\n\" +\n",
    "                          sin_lecto)\n",
    "\n",
    "propmt_2shot_con_lecto =( header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" + header_A1 + \"\\n\" + ejemplo_2_A1 + \"\\n\" +\n",
    "                          header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" + header_A2 + \"\\n\" + ejemplo_2_A2 + \"\\n\" +\n",
    "                          header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" + header_B1 + \"\\n\" + ejemplo_2_B1 + \"\\n\" +\n",
    "                          header_B2 + \"\\n\" + ejemplo_1_B2 + \"\\n\" + header_B2 + \"\\n\" + ejemplo_2_B2 + \"\\n\" +\n",
    "                          header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" + header_C1 + \"\\n\" + ejemplo_2_C1 + \"\\n\" +\n",
    "                          header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" + header_C2 + \"\\n\" + ejemplo_2_C2 + \"\\n\" +\n",
    "                          con_lecto)\n",
    "\n",
    "prompt_2shot_sin_lecto_correccion = propmt_2shot_sin_lecto + \"\\n\" + correccion\n",
    "prompt_2shot_con_lecto_correccion = propmt_2shot_con_lecto + \"\\n\" + correccion\n",
    "\n",
    "prompt_2shot_sin_lecto_sacando_b2 =(header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" + header_A1 + \"\\n\" + ejemplo_2_A1 + \"\\n\" +\n",
    "                                    header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" + header_A2 + \"\\n\" + ejemplo_2_A2 + \"\\n\" +\n",
    "                                    header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" + header_B1 + \"\\n\" + ejemplo_2_B1 + \"\\n\" +\n",
    "                                    header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" + header_C1 + \"\\n\" + ejemplo_2_C1 + \"\\n\" +\n",
    "                                    header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" + header_C2 + \"\\n\" + ejemplo_2_C2 + \"\\n\" +\n",
    "                                    sin_lecto)\n",
    "\n",
    "prompt_2shot_con_lecto_sacando_b2 =(header_A1 + \"\\n\" + ejemplo_1_A1 + \"\\n\" + header_A1 + \"\\n\" + ejemplo_2_A1 + \"\\n\" +\n",
    "                                    header_A2 + \"\\n\" + ejemplo_1_A2 + \"\\n\" + header_A2 + \"\\n\" + ejemplo_2_A2 + \"\\n\" +\n",
    "                                    header_B1 + \"\\n\" + ejemplo_1_B1 + \"\\n\" + header_B1 + \"\\n\" + ejemplo_2_B1 + \"\\n\" +\n",
    "                                    header_C1 + \"\\n\" + ejemplo_1_C1 + \"\\n\" + header_C1 + \"\\n\" + ejemplo_2_C1 + \"\\n\" +\n",
    "                                    header_C2 + \"\\n\" + ejemplo_1_C2 + \"\\n\" + header_C2 + \"\\n\" + ejemplo_2_C2 + \"\\n\" +\n",
    "                                    con_lecto)\n",
    "\n",
    "#DESCRIPTORES:\n",
    "propmt_descriptores =(header_des_A1 + \"\\n\" + descriptores_A1 + \"\\n\" +\n",
    "                      header_des_A2 + \"\\n\" + descriptores_A2 + \"\\n\" +\n",
    "                      header_des_B1 + \"\\n\" + descriptores_B1 + \"\\n\" +\n",
    "                      header_des_B2 + \"\\n\" + descriptores_B2 + \"\\n\" +\n",
    "                      header_des_C1 + \"\\n\" + descriptores_C1 + \"\\n\" +\n",
    "                      header_des_C2 + \"\\n\" + descriptores_C2 + \"\\n\" +\n",
    "                      propmt_descriptores)\n",
    "\n",
    "propmt_descriptores_sin_B2 =( header_des_A1 + \"\\n\" + descriptores_A1 + \"\\n\" +\n",
    "                              header_des_A2 + \"\\n\" + descriptores_A2 + \"\\n\" +\n",
    "                              header_des_B1 + \"\\n\" + descriptores_B1 + \"\\n\" +\n",
    "                              header_des_C1 + \"\\n\" + descriptores_C1 + \"\\n\" +\n",
    "                              header_des_C2 + \"\\n\" + descriptores_C2 + \"\\n\" +\n",
    "                              propmt_descriptores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687217fe-81f1-4a30-96e2-5b5465a4426f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Definicion de los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45917cb0-61d6-4aa3-bd5d-9f281309f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento_0 = propmt_0shot_sin_lecto\n",
    "experimento_1 = propmt_0shot_con_lecto\n",
    "experimento_2 = prompt_0shot_sin_lecto_correccion\n",
    "experimento_3 = prompt_0shot_con_lecto_correccion\n",
    "experimento_4 = propmt_1\n",
    "experimento_5 = propmt_2\n",
    "experimento_6 = propmt_3\n",
    "experimento_7 = propmt_4\n",
    "experimento_8 = propmt_5\n",
    "experimento_9 = propmt_1shot_sin_lecto\n",
    "experimento_10 = propmt_1shot_con_lecto\n",
    "experimento_11 = prompt_1shot_sin_lecto_correccion\n",
    "experimento_12 = prompt_1shot_con_lecto_correccion\n",
    "experimento_13 = prompt_1shot_sin_lecto_sacando_b2\n",
    "experimento_14 = prompt_1shot_con_lecto_sacando_b2\n",
    "experimento_15 = propmt_2shot_sin_lecto\n",
    "experimento_16 = propmt_2shot_con_lecto\n",
    "experimento_17 = prompt_2shot_sin_lecto_correccion\n",
    "experimento_18 = prompt_2shot_con_lecto_correccion\n",
    "experimento_19 = prompt_2shot_sin_lecto_sacando_b2\n",
    "experimento_20 = prompt_2shot_con_lecto_sacando_b2\n",
    "experimento_21 = propmt_descriptores\n",
    "experimento_22 = propmt_descriptores_sin_B2\n",
    "\n",
    "experimentos = [experimento_0]\n",
    "#experimentos = [experimento_1, experimento_2, experimento_3, experimento_4, experimento_5, experimento_6, experimento_7, experimento_8, experimento_9, experimento_10, experimento_11, experimento_12, experimento_13, experimento_14, experimento_15, experimento_16, experimento_17, experimento_18, experimento_19, experimento_20, experimento_21, experimento_22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332df21-dcb9-4553-9793-cd14b0687d9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fe89e9-1abf-468b-a7c4-2d93cbcd6ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100086ff5e9d4ce0a83bdea66e227e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Orca-2-7b\",\n",
    "    device_map='auto',           # Automatically maps model layers to available devices\n",
    "    offload_folder=\"./offload\",  # Specifies a folder for offloading layers to disk if needed\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load the tokenizer (use the slow tokenizer as recommended)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/Orca-2-13b\",\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab1ad0-35d8-4e54-b41a-60f9316e582c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ejecucion del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33eaf6-9892-4543-85ec-c5c22a9e837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "j = 0\n",
    "for experimento in experimentos:\n",
    "    system_message = experimento\n",
    "    filename =f'experimento_{j}real.csv'\n",
    "    batch_texts = textos_metricas['text']\n",
    "    predicted_labels = []\n",
    "\n",
    "    for text in batch_texts:\n",
    "        prompt = f\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{text}<|im_end|>\\n<|im_start|>assistant\"\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "        output_ids = model.generate(inputs[\"input_ids\"], max_new_tokens=20)\n",
    "        response = tokenizer.batch_decode(output_ids)[0]\n",
    "        \n",
    "        match = re.search(r'<\\|im_start\\|> assistant\\s*(.*)', response)\n",
    "        if match:\n",
    "            classification = match.group(1).strip() \n",
    "        else :\n",
    "            classification ='Unknown'\n",
    "            print(\"fallo primer filtro\")\n",
    "        \n",
    "        match = re.search(r'\\b(A1|B1|C1|A2|B2|C2)\\b', classification)\n",
    "        classification_filtered = match.group() if match else 'Unknown'\n",
    "        \n",
    "        # Append the predicted classification to the list\n",
    "        predicted_labels.append(classification_filtered)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        del response  # Delete the output after each step to free memory\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Predicted Labels'])\n",
    "        for label in predicted_labels:\n",
    "            writer.writerow([label])\n",
    "    \n",
    "    FileLink(filename)\n",
    "    j = j + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

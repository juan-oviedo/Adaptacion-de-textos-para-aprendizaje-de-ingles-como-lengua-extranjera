{"cells":[{"cell_type":"markdown","metadata":{"id":"WGKKR_OkjsrE"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"c_gK8v_bYpil","executionInfo":{"status":"ok","timestamp":1733224825616,"user_tz":180,"elapsed":8483,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["import sklearn.metrics as sk_metrics\n","import sklearn.model_selection as sk\n","import seaborn\n","import matplotlib.pyplot as plt\n","import numpy\n","import pandas as pd\n","import csv\n","import os\n","import collections\n","from google.colab import files\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"H7jruQNejyps"},"source":["## Nombre"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"sF07DHWkcu4S","executionInfo":{"status":"ok","timestamp":1733228165354,"user_tz":180,"elapsed":273,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["#nombre_archivo = \"resultados_llama\"\n","#carpeta = \"clasificacion llama\"\n","\n","#nombre_archivo = \"resultados_orca\"\n","#carpeta = \"clasificacion orca\"\n","\n","nombre_archivo = \"resultados_bert\"\n","carpeta = \"bert\"\n","\n","folder_name = \"mineria de datos/resultados/\"\n","exp_min = 0\n","exp_max = 1"]},{"cell_type":"markdown","metadata":{"id":"QkT-5B_hkWUj"},"source":["## Carga de los datos y division del data set"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EwzxbuxpcU2B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733224829297,"user_tz":180,"elapsed":3695,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}},"outputId":"0386ee35-7999-44aa-c129-e37874e5ca95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/amontgomerie/cefr-levelled-english-texts\n","License(s): CC0-1.0\n","Downloading cefr-levelled-english-texts.zip to /content\n","  0% 0.00/1.36M [00:00<?, ?B/s]\n","100% 1.36M/1.36M [00:00<00:00, 61.4MB/s]\n","Archive:  cefr-levelled-english-texts.zip\n","  inflating: cefr_leveled_texts.csv  \n"]}],"source":["# Check if the zip file is present and has been unzipped\n","if not os.path.exists(\"cefr-levelled-english-texts.zip\"):\n","    # Download the dataset if the zip file is not present\n","    !kaggle datasets download -d amontgomerie/cefr-levelled-english-texts\n","\n","if not os.path.exists(\"cefr_leveled_texts.csv\"):  # Adjust this to match the folder name after unzipping\n","    # Unzip the file if the unzipped folder does not exist\n","    !unzip cefr-levelled-english-texts.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wj304kOncYIz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733224829612,"user_tz":180,"elapsed":323,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}},"outputId":"fe971643-30ed-437c-df4e-c99ba82377b6"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-fc31009e116c>:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df_balanced = df.groupby('label').apply(lambda x: x.sample(n=min_samples, random_state=60)).reset_index(drop=True)\n"]}],"source":["# Load the CSV file into a DataFrame\n","df = pd.read_csv('cefr_leveled_texts.csv')\n","\n","# Get the minimum number of samples in any class\n","min_samples = df['label'].value_counts().min()\n","\n","# Downsample each class to have the same number of samples as the smallest class\n","df_balanced = df.groupby('label').apply(lambda x: x.sample(n=min_samples, random_state=60)).reset_index(drop=True)\n","\n","distribution = df_balanced['label'].value_counts()\n","train, div = sk.train_test_split(df_balanced, test_size=0.2, random_state=70)\n","dev, holdout = sk.train_test_split(div, test_size=0.5, random_state=50)\n","\n","train = train.reset_index(drop=True)\n","dev = dev.reset_index(drop=True)\n","holdout = holdout.reset_index(drop=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dzpbO1_nuuQm","executionInfo":{"status":"ok","timestamp":1733224829613,"user_tz":180,"elapsed":41,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["true_list = pd.concat([dev, train])\n","true_labels = true_list['label'].tolist()"]},{"cell_type":"markdown","metadata":{"id":"EN5AvRxZkUI0"},"source":["## Carga de los experimentos"]},{"cell_type":"code","source":["drive.mount('/content/drive', force_remount=False)\n","folder_root = \"/content/drive/My Drive/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hro7jjg-NSg6","executionInfo":{"status":"ok","timestamp":1733228169968,"user_tz":180,"elapsed":2292,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}},"outputId":"9448726d-88e9-4e3c-ccaa-d39461d555d8"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":37,"metadata":{"id":"85w-GTmRZ7Tu","executionInfo":{"status":"ok","timestamp":1733228169969,"user_tz":180,"elapsed":15,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["file_path = os.path.join(folder_root, folder_name, carpeta)\n","\n","all_results = []\n","for i in range (exp_min, exp_max + 1):\n","  file_name= file_path + f\"/experimento_{i}.csv\"\n","  df = pd.read_csv(file_name)\n","  labels_list = df['Predicted Labels'].tolist()\n","  all_results.append(labels_list)"]},{"cell_type":"markdown","metadata":{"id":"swVptParky_1"},"source":["## Metricas de Interes"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"NB9k-DIkC7OP","executionInfo":{"status":"ok","timestamp":1733228187011,"user_tz":180,"elapsed":258,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["# Map CEFR levels to numerical values\n","cefr_mapping = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n","\n","def weighted_hit_ratio(true_labels, predicted_labels, weight_M):\n","    total_hits = 0\n","    total_penalty = 0\n","\n","    for true_label, predicted_label in zip(true_labels, predicted_labels):\n","\n","        if predicted_label == 'Unknown' or predicted_label == 'LABEL_0':\n","            continue\n","\n","        true_value = cefr_mapping[true_label]\n","        predicted_value = cefr_mapping[predicted_label]\n","\n","        # Calculate the distance between actual and predicted classes\n","        distance = abs(true_value - predicted_value)\n","\n","        if distance == 0:\n","            # It's a hit, so add weight M\n","            total_hits += weight_M\n","        else:\n","            # It's an error, so add the penalty (the distance)\n","            total_penalty += distance\n","\n","    # Weighted hit ratio = Total hits / (Total hits + Total penalties)\n","    if total_hits + total_penalty == 0:\n","        return 0  # To avoid division by zero\n","    return total_hits / (total_hits + total_penalty)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"znL_bd87OMV7","executionInfo":{"status":"ok","timestamp":1733228187263,"user_tz":180,"elapsed":10,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}}},"outputs":[],"source":["def aproximate_acuracy(true_labels, predicted_labels):\n","    total_hits = 0\n","    total_penalty = 0\n","\n","    for true_label, predicted_label in zip(true_labels, predicted_labels):\n","\n","        if predicted_label == 'Unknown' or predicted_label == 'LABEL_0':\n","            continue\n","\n","        true_value = cefr_mapping[true_label]\n","        predicted_value = cefr_mapping[predicted_label]\n","\n","        # Calculate the distance between actual and predicted classes\n","        distance = abs(true_value - predicted_value)\n","\n","        if distance == 0:\n","            # It's a hit, so add weight M\n","            total_hits += 1\n","        elif distance == 1:\n","            total_hits += 0.5\n","\n","    return total_hits / len(true_labels)"]},{"cell_type":"markdown","metadata":{"id":"w4_rUFIHlLYy"},"source":["## Calcular metricas y armar csv"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"JzgIM2dlYzPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733228188741,"user_tz":180,"elapsed":381,"user":{"displayName":"JUAN CRUZ OVIEDO FERREYRA","userId":"04532813389617512917"}},"outputId":"2896471d-3f1f-4a79-d2d4-50c721c12ecb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["# Initialize a list to store metrics for each experiment\n","metrics_data = []\n","\n","hit_weight = 2\n","\n","# Define class labels for F1 scores per class\n","class_labels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\", 'Unknown']\n","\n","for idx, results in enumerate(all_results):\n","  #calculate accuracy\n","  accuracy = sk_metrics.accuracy_score(true_labels, results)\n","\n","  #calculate weighted_hit_ratio\n","  hit_ratio = weighted_hit_ratio(true_labels, results, hit_weight)\n","  aproximate = aproximate_acuracy(true_labels, results)\n","\n","  # Calculate F1 scores\n","  micro_f1 = sk_metrics.f1_score(true_labels, results, average='micro')\n","  macro_f1 = sk_metrics.f1_score(true_labels, results, average='macro')\n","\n","  # Calculate F1 scores for each class\n","  f1_per_class = sk_metrics.f1_score(true_labels, results, labels=[\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\", 'Unknown'], average=None)\n","\n","  # Calculate precision and recall for each class\n","  precision_per_class = sk_metrics.precision_score(true_labels, results, labels=class_labels, average=None)\n","  recall_per_class = sk_metrics.recall_score(true_labels, results, labels=class_labels, average=None)\n","\n","  # Count the predicted labels for each class\n","  predicted_counts = collections.Counter(results)\n","  true_counts = collections.Counter(true_labels)\n","\n","  # Ensure that all class labels are present in the counts, even if some classes are missing\n","  predicted_counts = [predicted_counts.get(label, 0) for label in class_labels]\n","  true_counts = [true_counts.get(label, 0) for label in class_labels]\n","\n","  # Append the metrics to the list (one row for each experiment)\n","  # For each class, the order will be: Predicted Count, Precision, Recall, F1\n","  row = [f'Experiment {idx}', accuracy, aproximate, hit_ratio, macro_f1, micro_f1]  # Common metrics\n","  for i in range(len(class_labels)):\n","      row += [predicted_counts[i], true_counts[i], precision_per_class[i], recall_per_class[i], f1_per_class[i]]\n","\n","  metrics_data.append(row)\n","\n","\n","# Save metrics to a CSV file\n","filename = file_path + f\"/{nombre_archivo}.csv\"\n","with open(filename, 'w', newline='') as csvfile:\n","  writer = csv.writer(csvfile)\n","\n","  # Write the header\n","  header = ['Experiment', 'Accuracy', 'Accuracy aproximada', 'Accuracy Pesada', 'Macro-F1', 'Micro-F1']\n","  for label in class_labels:\n","      header += [f'{label} Predicted Count', f'{label} cantidad de mustras de una clase en el experimento', f'{label} Precision', f'{label} Recall', f'{label} F1']\n","\n","  writer.writerow(header)\n","\n","  # Write the metrics data\n","  writer.writerows(metrics_data)"]},{"cell_type":"markdown","metadata":{"id":"mpDz6lAxkpBD"},"source":["## Matriz de confucion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GS0DUjyhxe_O"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm0yUyEtv4i8"},"outputs":[],"source":["for idx, results in enumerate(all_results):\n","  # Compute the confusion matrix\n","  conf_matrix = sk_metrics.confusion_matrix(true_labels, results)\n","\n","  # Plot the confusion matrix as a heatmap\n","  plt.figure(figsize=(8, 6))\n","  seaborn.heatmap(\n","      conf_matrix, annot=True, fmt='d', cmap='Blues',\n","      xticklabels=numpy.unique(true_labels),\n","      yticklabels=numpy.unique(true_labels))\n","  plt.xlabel('Predicted label')\n","  plt.ylabel('True label')\n","  plt.title(f'Confusion Matrix para exp: {idx}')\n","\n","  file_path = f'/content/drive/My Drive/mineria de datos/matriz de confucion/llama/{idx}.png'  # Change path as needed\n","  plt.savefig(file_path, dpi=600)\n","  print(f\"Plot saved to {file_path}\")"]}],"metadata":{"colab":{"collapsed_sections":["WGKKR_OkjsrE","H7jruQNejyps","QkT-5B_hkWUj","EN5AvRxZkUI0","mpDz6lAxkpBD","swVptParky_1","w4_rUFIHlLYy"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}